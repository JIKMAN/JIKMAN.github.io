---
title:  "[Hadoop] HBase 개념"

categories:
  - Hadoop
tags:
  - [hadoop, Hbase]
toc: true
toc_sticky: true
---

## HBase

HBase(Hadoop database)는 하둡 기반의 분산 데이터베이스입니다.

HDFS위에서 작동하기 때문에, HDFS의 데이터의 가용성과 확장성을 그대로 이용 할 수 있습니다.

 데이터베이스 CAP 이론에서 HBASE는 CP 타입(Consistency & Partition tolerance) 시스템으로 구글의 **BigTable**과 유사한 기능을 제공한다. 즉, 컬럼 단위의 데이터 저장, 압축, 메모리 작업 Bloom 필터등을 제공하며 Hadoop에서 실행되는 MapReduce의 입력/출력을 사용 할 수 있습니다. 기본적으로 Java API를 통해서 접근 할 수 있지만 REST, Avro 혹은 Thrift 게이터웨이를 통한 접근도 가능합니다.

> **Hbase의** **특징**

 • 선형 확장성이 있다.

 • 읽기와 쓰기의 일관성을 제공

 • 하둡과 연계하여 source가 되기도 하고 destination이 되기도 한다.

 • 클러스터를 통한 데이터의 복제 제공



### Architecture

**1. Master Server**

  • **Region**을 **regeion** **서버에 할당하고 할당** 업무를 위한 zookeeper의 도움을 받는 작업을 수행

  • Region서버에 퍼져있는 **region들의 로드밸런싱을 수행**

  • 로드밸런싱 조율을 통해 클러스터의 상태 유지 수행

![img](https://t1.daumcdn.net/cfile/tistory/9924793359C343B013)



  • 테이블의 생성이나 column family의 생성과 같은 **스키마의 변화나 메타데이터 연산**을 책임진다.

![img](https://t1.daumcdn.net/cfile/tistory/9950A93359C343D61C)



**2. Regions Server**

  • **클라이언트와 통신을 하고 데이터 관련 연산**을 관리한다.

  • 내부 region의 읽기와 쓰기 요청을 관리한다.

  • Region의 크기는 region크기의 threshold에 의해 결정 된다.

  • 내부에 메모리 저장소와 HFile을 가지고 있다.

  • 메모리 저장소는 캐시와 같은 동작을 한다.

![img](https://t1.daumcdn.net/cfile/tistory/99F6813359C3440924)



  • 처음 데이터를 저장하면 memstore에 저장이 되고 이후에 Hfile에 블록으로 저장 후 메모리는 Flush!

![img](https://t1.daumcdn.net/cfile/tistory/9941543359C3444936)



**3. Zookeeper**

  • 설정 정보의 관리, 분산처리의 동기화 등을 제공해주는 오픈소스 프로젝트

  • 임시 노드를 다른 region server에게 제안하면 마스터서버는 가용서버가 있는지 확인 후 사용한다.

  • 가용성을 추가 하여 서버 실패나 네트워크 분할등을 추적할 수 있다.

  • **클라이언트가** **region**에 통신하려면 **zookeeper**을 통해야 한다.

  • Pseudo 와 standalone모드에서는 hbase 자체가 zookeeper의 기능도 담당한다.



### HBASE vs RDBMS

| **HBase**                                                    | **RDBMS**                                                 |
| ------------------------------------------------------------ | --------------------------------------------------------- |
| 스키마가 없다, 고정 컬럼 스키마의 개념이 없다. column families만으로 이용된다. | 테이블의 구조를 기술하는 스키마에의해서 이용된다.         |
| 수평적으로 확장성이 있어 큰 테이블에 적합하다.               | 확장하기 어려우며, 크기가 작은 테이블을 위해 생성 되었다. |
| Hbase에는 Transaction이 존재하지 않음                        | Transaction이 존재                                        |
| 비 일반화된 데이터가 적재된다.                               | 일반화된 데이터가 적재된다.                               |
| 구조화된 데이터보다 덜 구조화된 데이터가 적합하다.           | 구조화된 데이터에 적합하다.                               |
| get / put / scan 등                                          | SQL                                                       |
| MapRduce Join 활용                                           | Join에 최적화 됨                                          |
| Rowkey만 인덱스 지원                                         | 임의 컬럼에 대한 인덱스 지원                              |
| 초당 수십만건 Read/Write                                     | 초당 수천건 Read/Write                                    |
| 단일로우 트랜잭션 보장                                       | 다중 로우 트랜잭션 보장                                   |



### **HBase 용어설명**

 **Table 구조**

 ![img](https://t1.daumcdn.net/cfile/tistory/99EE283359C34FE50E)





| **용어**             | **설명**                                                     |
| -------------------- | ------------------------------------------------------------ |
| **Table**            | 다중 로우로 구성된 집합                                      |
| **Row**              | HBase에서 한 로우는 로우 키와 하나 또는 그 이상의 칼럼과 값으로 구성된다. 로우는 저장될때 로우키를 기준으로 알파벳순으로 정렬되어 저장된다. 이러한 이유로 로우 키는 설계에서 매우 중요하다. 이러한 저장 방식은 연관된 로우끼리 가깝게 배치하려는 목적이다. 가장 일반적인 로우키의 패턴은 웹사이트 도메인이다. 만약 로우키가 도메인이라면 도메인 역순으로 저장할 수 있을 것이다. ( org.apache.www, org.apache.main). 이러한 방식으로 저장하면 테이블에서 모든 아파치 도메인은 근처에 저장되게 된다. 이러한 방식은 서브도메인의 첫글자를 기준으로 저장되는 것 보다 좋은 방식이 될 것이다. |
| **Column**           | HBase 칼럼은 column family 와 column qualifier로 구성된다. 해당 항목들은 콜론(:)으로 구분된다. |
| **Column Family**    | 컬럼 패밀리란 컴럼과 값의 집합을 성능상의 이유로 물리적으로 값은 장소에 배치한 것을 의미한다. 각 컬럼 패밀리는 저장된 프로퍼티의 집합을 가진다. 각 테이블로 로우는 주어진 컬럼 패밀리에 저장할 것이 없더라도 같은 칼럼 패밀리들을 가진다. 컬럼 패밀리는 테이블이 생성될때 명시되며, 내부 파일시스템에 저장되는 방식에 영향을 준다. 그러므로, 컬럼 패밀리는 스키마 설계에서 중요한 고려 사항이다. |
| **Column Qualifier** | 컬럼 수식어란 데이터를 인덱스를 제공하기 위해 컬럼 패밀리에 추가된 것이다. 주어진 컬럼 패밀리 content의 즉 컬럼 수석어는 content:html, content:pdf 일 수 있다. 컬럼 패밀리는 테이블이 생성될때 고정되지만, 컬럼 수식어는 로우간에 가변적이고 다를 수 있다. |
| **Cell**             | 셀은 로우, 컬럼패밀리, 컬럼 수식어의 집합이며, 값의 버젼을 표한하기 위해서 timestamp 값을 포함한다. 셀은 값은 해석되지 않은 바이트 배열이다. |
| **Timestamp**        | Timestamp는 주어진 값의 버젼 식별자로서 각 값과 나란히 기록된다. 기본적으로 timestamp는 데이터가 기록될때 RegionServer의 시간이며, 셀에 데이터를 넣을때 명시할 수도 있다. Timestamp를 직접적으로 조작하는 것은 특별한 경우이며, 일반적인 경우에는 권장하지 않는다. 어플리케이션 레벨에서 timestamp를 인코딩하는 것은 권장하는 패턴이다. |



 **Put Method**

| **구분**                                                     | **설명**                                                  |
| ------------------------------------------------------------ | --------------------------------------------------------- |
| **Single Puts**                                              | Put Instance를 생성하기 위해서는 row key를 제공해야 한다. |
| HBase의 row는 고유한 row key로 식별하며, row key 타입은 java 데이터 타입인 byte array로 저장된다. |                                                           |
| Column을 추가하려면 add( )를 사용한다.                       |                                                           |
| 특정 cell이 존재하는지 알아보려면 has( )를 사용한다.         |                                                           |
| 클라이언트 코드에서 설정 파일에 접근하려면 HBaseConfiguration class를 사용한다. |                                                           |
| **KeyValue class**                                           | Row 단위가 아닌 특정 cell 단위의 모든 정보를 반환한다.    |
| 좌표계처럼 row key, column family, column qualifier, timestamp가 3차원 공간의 한 지점을 가리키는 모습이다. |                                                           |
| 주로 KEY 데이터간의 비교/검증/복제 등에 사용한다.            |                                                           |
| 저장공간을 최소화하여 효율적으로 데이터 저장하고, 빠른 데이터 연산을 제공하기 위해 byte array 타입을 사용한다. |                                                           |
| **List of Puts**                                             | 연산을 일괄로 한데 묶어서 처리한다.                       |
| 리스트 기반의 입력은 서버 측에서 입력 연산이 적용 되는 순서를 제어 할 수 없다. |                                                           |
| 데이터 입력 순서를 보장해야 하는 경우에는 작게 나눈 후 Write cache를 명시적으로 flush해야 한다. |                                                           |



 **Get Method**

| **구분**                                                     | **설명**                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Single Gets**                                              | 특정 row 하나를 대상으로 수행되지만 row 내에서는 column/cell 제한이 없다. |
| 버전 개수는 1로 최근 값만 리턴 받고, setMaxVersions( )를 통하여 지정 가능하다. |                                                              |
| **Result class**                                             | get( )을 통하여 데이터를 읽어 들일 때 get 조건에 만족하는 모든 cell을 담고 있는 Result class의 instance를 반환한다. |
| 서버에서 반환한 모든 column family, column qualifier, timestamp 접근 수단을 제공한다. |                                                              |
| **List of Gets**                                             | 하나의 요청으로 여러 개의 row를 요구할 때 사용된다.          |
| get instance와 동일한 배열을 반환, 예외발생 중 하나로만 동작한다. |                                                              |



 **Delete Method**

| **구분**                                                     | **설명**                                                     |
| ------------------------------------------------------------ | ------------------------------------------------------------ |
| **Single Deletes**                                           | delete class를 생성하려면 삭제 대상 row key를 입력해야 한다. |
| rowlock 파라미터를 추가 선택하여 동일한 row를 두 번 이상 변경하고자 할 때 사용자 자신의 락을 설정한다. |                                                              |
| 전체 family 및 그에 속한 모든 column 삭제, timestamp 지정이 가능하다. |                                                              |
| **List of Deletes**                                          | put list와 유사하게 동작한다.                                |
| Remote 서버에서는 데이터가 삭제되는 순서를 보장할 수 없다는 것을 주의한다. |                                                              |
| table.delete(deletes) 수행 시 실패한 작업은 deletes에 남게 되며, Exception 처리는 try/catch 구문을 이용한다. |                                                              |



**Reference**

[https://cyberx.tistory.com/164](https://cyberx.tistory.com/164)

[https://www.joinc.co.kr/w/man/12/hadoop/hbase/about](https://www.joinc.co.kr/w/man/12/hadoop/hbase/about)